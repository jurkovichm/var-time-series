---
title: "Vector Autoregressive Models"
author: "Marko Jurkovich & Matt Zacharski"
date: "6/3/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(vars)
```

### Introduction

- Motivated by the goal of predicting a time series via a correlated partner time series, we will investigate Vector Autoregressive models (AKA VAR(p) models). 

- Why VAR models exist, what they're better at than AR models. In predictions they don't just include a variable at time t, but take all previous observations into account.

### Model

There are three main forms of VAR models: reduced form, recursive, and structural. The reduced form defines each variable in the vector of time series as the function of its own lags and the lags of all other variables, with an error term. The error terms from each equation can theoretically be correlated. Recursive VAR models are constructed so that the error terms for a variable are uncorrelated to the prior variables' errors. This is done by adding the  preceding variables' current values to the typical VAR equation. The structural VAR models are distinguished in that they make assumptions of the "causal structure" of the the data allow shocks to be indentified. These shocks would otherwise be incorporated into error terms in recursive and reduced models.

A reduced VAR(1) model with three variables can be modeled as such:

$$x_{t,1} = \alpha_1 + \beta_{1,1}x_{t-1,1} +\beta_{1,2}x_{t-1,2} + \beta_{1,3}x_{t-1,3}+\epsilon_{t,1}$$
$$x_{t,2} = \alpha_2 + \beta_{2,1}x_{t-1,1} +\beta_{2,2}x_{t-1,2} + \beta_{2,3}x_{t-1,3}+\epsilon_{t,2}$$
$$x_{t,1} = \alpha_1 + \beta_{3,1}x_{t-1,1} +\beta_{3,2}x_{t-1,2} + \beta_{3,3}x_{t-1,3}+\epsilon_{t,3}$$

### Estimation

"adding variables to the VAR creates complications, because the number of VAR parameters increases as the square of the number of variables: a nine-variable, four-lag VAR has 333 unknown coefficients" https://pubs.aeaweb.org/doi/pdf/10.1257/jep.15.4.101

### Diagnostics

### Forecasting

### Data Example

### Bibliography

### Code Appendix

```{r}
btc<-read_csv('BTC-USD.csv')
eth<-read_csv('ETH-USD.csv')
doge<-read_csv('DOGE-USD.csv')
eth <- eth[-1827,]

closing_prices <- as.data.frame(cbind(btc$Close, eth$Close, doge$Close))

closing_prices$Date <- btc$Date

colnames(closing_prices) <- c('BTC', 'ETH', 'DOGE', 'Date')

plot(closing_prices$Date, closing_prices$BTC, type = 'l')
lines(closing_prices$Date, closing_prices$ETH, type = 'l', col = 'red')
lines(closing_prices$Date, closing_prices$DOGE, type = 'l', col = 'dark green')

#plot with standardized data?


btc_scale <- scale(closing_prices$BTC)
doge_scale <- scale(closing_prices$DOGE)
eth_scale <- scale(closing_prices$ETH)

scaled_data <- data.frame(Date = closing_prices$Date,
                          scaled_bth = btc_scale[,1],
           scaled_eth = eth_scale[,1],
           scaled_doge = doge_scale[,1])

plot(scaled_data$Date, scaled_data$scaled_bth, type = 'l')
lines(scaled_data$Date, scaled_data$scaled_eth, type = 'l', col = 'red')
lines(scaled_data$Date, scaled_data$scaled_doge, type = 'l', col = 'dark green')

#try to make the plots kinda stationary maybe?
plot(scaled_data$Date[c(-1,-2)], diff(scaled_data$scaled_bth, 2), type = 'l')
lines(scaled_data$Date[c(-1,-2)], diff(scaled_data$scaled_eth, 2), type = 'l', col = 'red')
lines(scaled_data$Date[c(-1,-2)], diff(scaled_data$scaled_doge, 2), type = 'l', col = 'dark green')
#eh decent I guess

scaled_data <- scaled_data[,-1]

scaled_data_clean <- na.omit(scaled_data)


fitvar = VAR(scaled_data_clean, p=2, type="both")

summary(fitvar)

acf(residuals(fitvar))


VARselect(scaled_data_clean, lag.max=12, type="const")[["selection"]]
ts_obj <- as.ts(scaled_data_clean)

var12 <- VAR(ts_obj, p=12, type="const")
serial.test(var12, lags.pt=12, type="PT.asymptotic")

library(forecast)
forecast(var12) %>%
  autoplot() + xlab("Year")

t <- as.data.frame(forecast(var12))

t$`Point Forecast` * attr(t$`Point Forecast`, 'scaled:scale') + attr(t$`Point Forecast`, 'scaled:center')


```